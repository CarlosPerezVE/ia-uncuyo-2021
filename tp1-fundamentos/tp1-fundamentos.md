Nombre: Carlos Perez

Legajo: 13245

**Inteligencia Artificial Débil:**

¿Puede una máquina actuar con inteligencia? Esta pregunta ha sido durante años la razón de debate entre filósofos de la computación, en los cuales tenemos argumentos tan fuertes y negativos como el de Kenneth M. Sayre:

_&quot;La Inteligencia Artificial abordada desde dentro del culto al computacionalismo no tendrá ni siquiera un atisbo de fantasma de posibilidad de producir resultados duraderos... Es hora de desviar los esfuerzos de los investigadores en IA, y la gran cantidad de dinero disponible para su soporte, y dirigirse a caminos distintos del enfoque computacional.&quot;_

La IA es un concepto muy amplio que engloba extensas variables, por lo cual si esta es posible o no está atada a la definición que le demos a tanto la inteligencia artificial como al de inteligencia misma. Si tomamos la definición esencial de la IA, esta consiste en la búsqueda del mejor programa agente en una arquitectura específica, entonces podemos llegar al postulado que se define como:

_&quot;La IA es posible por definición: para cualquier arquitectura digital de k bits de almacenamiento existirán exactamente 2k programas agente y todo lo que habrá que hacer para encontrar el mejor es enumerarlos y probar todos ellos&quot;_

Si bien esta es una solución teórica, debido que para una k grande puede que no logremos encontrar una solución práctica, cumple el objetivo de encontrar una definición específica de lo que es la IA. Sin embargo la filosofía de la inteligencia artificial está centrada en no solo definir la inteligencia artificial, si no definirla mediante la comparación con la inteligencia humana, por lo que surge la pregunta: **¿Pueden pensar las máquinas?** De nuevo estamos ante una pregunta en la cual la respuesta depende de las definiciones que demos a un concepto, en este caso _pensar_, y debido a que el concepto de máquina pensante lleva algo más de 50 años con nosotros, esto ha sido tiempo suficiente para encontrar una definición específica del significado de _pensar._

En 1950, Alan Turing sugirió que en vez de preguntar si las máquinas pueden pensar, deberíamos preguntar si las máquinas pueden aprobar un test de inteligencia inductiva, es decir un test de comportamiento, conocido como el Test de Turing. La prueba se realiza para que el programa mantenga una conversación durante cinco minutos con un interrogador. Este tiene que averiguar si la conversación se está llevando a cabo con un programa o con una persona, si el programa engaña al interlocutor un 30 por ciento del tiempo, este programa pasará la prueba. Si nos guiamos por esta definición, hoy en 2021 no hay ningún programa en ninguna arquitectura que haya completado este test frente a jueces con conocimiento sobre el área.

Turing examinó además una amplia gama de objeciones ante la posibilidad de las máquinas inteligentes, algunas de ellas son:

1. El argumento de la incapacidad:

Este argumento afirma que una máquina nunca puede hacer cosas como ser amable, ser guapo, simpático, tener iniciativas, sentido del humor, cometer errores, aprender de la experiencia, tener tanta diversidad de comportamientos como el hombre.

Turing se vio obligado a utilizar su intuición para listar este tipo de actividades. Hoy en día muchas de estas actividades son de hecho, posibles para un computador, los programas juegan ajedrez, damas, y a otros muchos juegos, comprueban errores ortográficos, conducen coches y un largo etcétera de cosas que hacen tan bien como un ser humano (Y en muchos casos, mejor). Pero esto no significa que los computadores utilizan la intuición y el entendimiento para realizar estas tareas, y también es cierto que existen muchas tareas en la actualidad en las que las computadoras no sobresalen.

1. La objeción matemática:

Ciertas cuestiones matemáticas en principio no pueden ser respondidas por sistemas formales completos, el teorema de la incompletitud de Gödel es el ejemplo más conocido al respecto. Este dice que para cualquier sistema axiomático formal F lo suficientemente potente como para hacer aritmética, es posible construir una _Sentencia de Gödel_ con las siguientes propiedades:

- G(F) es una sentencia de F, pero no se puede probar dentro de F.
- Si F es consistente, entonces G(F) es verdadero.

Filósofos han afirmado que este teorema demuestra que las máquinas son mentalmente inferiores a los hombres, porque las máquinas son sistemas formales limitados por el teorema de la incompletitud, es decir no pueden establecer la verdad de su propia sentencia de Gödel. Existen algunos problemas con esta afirmación, aquí examinaremos 3.

En primer lugar el teorema de la incompletitud de Gödel se aplica sólo a sistemas formales que son lo suficientemente potentes como para realizar aritmética. Aquí se incluyen las máquinas Turing, y la afirmación se basa en que los computadores son máquinas de Turing.

En segundo lugar, un agente no debería avergonzarse de no poder establecer verdades de una sentencia aunque otros agentes si pueden, por ejemplo un ser humano no puede calcular la suma de 10 billones de números de 10 digitos, pero una computadora si, eso no quiere decir que el ser humano no tenga la habilidad de pensar. Diferentes arquitecturas para diferentes problemas.

Y finalmente, aunque reconozcamos que los computadores tienen limitaciones sobre lo que pueden demostrar, no existen evidencias de que los hombres sean inmunes a estas limitaciones.

1. El argumento de la informalidad:

&quot;El comportamiento humano es demasiado complejo para poder captarse mediante un simple juego de reglas&quot; Esta es una de las principales críticas hacia la IA, esta idea postula que como los computadores no pueden nada más que seguir un conjunto de reglas, no pueden generar un comportamiento tan inteligente como el de los hombres.

Esta postura se llama &quot;Good Old.Fashioned AI&quot;, la cual afirma que todo comportamiento inteligente puede ser capturado por un sistema que razona lógicamente, esta afirmación fue dada por Hubert Dreyfus en 1972, bajo su punto de vista, la pericia del hombre incluye el conocimiento de algunas reglas, pero solamente como un conocimiento base dentro del que operan los hombres. Proporciona como ejemplo el comportamiento social adecuado en ciertas situaciones entre humanos, como el elegir un regalo o en un contexto diferente, elegir un movimiento en una partida de ajedrez, él afirma que un maestro de ajedrez simplemente observa el tablero y analiza qué movimiento le exige este, es decir cosas que no están abiertas a la introspección de la mente consciente. Sin embargo esto no significa que no existan procesos de pensamientos inconscientes.

Dreyfus y Dreyfus (1986) proponen un proceso de adquisición de pericia en cinco etapas, comenzando con un procesamiento basado en reglas y terminando con la habilidad de seleccionar las respuestas correctas instantáneamente, este modelo se ha encontrado con algunos problemas, afortunadamente se han abordados cada uno de estos, algunos con éxito parcial y otro total.

- No se puede lograr una buena generalización de ejemplos sin un conocimiento básico. Se afirma que no se sabe cómo incorporar el conocimiento básico en el proceso de aprendizaje, sin embargo actualmente existen distintas técnicas de aprendizaje para programas de IA.

- El aprendizaje de redes neuronales es una forma de aprendizaje supervisado que requiere la identificación anterior de las entradas relevantes y las salidas correctas, eso quiere decir que no puede funcionar autónomamente.

- Los algoritmos de aprendizaje no funcionan bien con muchas funciones, si seleccionamos un subgrupo de éstas no existe una forma de añadir funciones nuevas.

- El cerebro es capaz de dirigir sus sensores para buscar la información relevante y procesarla para extraer aspectos relevantes para la situación actual

**Inteligencia artificial fuerte:**

&quot; Hasta que una máquina pueda escribir un soneto o componer un concierto porque sienta los pensamientos y las emociones, y no porque haya una lluvia de símbolos, podría reconocer que la máquina iguala al cerebro, es decir, no sólo escribirlo sino que sepa que lo ha hecho.&quot;

Palabras dadas por el profesor Geoffrey Jefferson en 1949. Esto es a lo que Turing llama el argumento de la consciencia, la máquina tiene que ser consciente de sus propias acciones y estados mentales. La respuesta de Turing a esta objeción se basa en que la cuestión no está bien definida al decir &quot;¿Pueden pensar las máquinas?&quot; y además Turing preguntó que porqué deberíamos insistir en un estándar más alto para las máquinas que el usado para los humanos, después de todo un ser humano no puede tener conciencia directa sobre los estados mentales de otras personas.

Turing afirma que si bien la cuestión de la consciencia es difícil, niega que esta sea relevante para la práctica de la IA, que se busca crear programas que se comporten de forma inteligente y no en si alguien que los declara reales o simulados. El ser humano ha tenido la capacidad ya desde hace décadas de crear componentes orgánicos de manera artificial, desde la sintetización de la urea, edulcorantes artificiales, pasando por áreas como la inseminación artificial y hasta la recreación artificial de obras de arte. Podemos asegurarnos de que esos componentes artificiales son iguales química o físicamente a sus contrapartes orgánicas, pero aún así existirá gente que asegure que una réplica no es igual al original.

Existen 2 teorías de los estados y los procesos mentales que influyen en la definición que estamos buscando:

1. La teoría del funcionalismo dice que un estado mental es cualquier condición causal inmediata entre la entrada y la salida, bajo esta teoría dos sistemas de procesos causales isomórficos tendrán los mismos estados mentales.

1. La teoría del naturalismo biológico dice que los estados mentales son características emergentes de alto nivel originadas por procesos neurológicos de bajo nivel en las neuronas, y lo que importan son sus propiedades, así pues los estados mentales no se pueden duplicar justo en la base de algún programa que tiene la misma estructura funcional

Estas dos teorías pueden ser aplicadas a distintos problemas filosóficos existentes tales como el **problema de la mente-cuerpo** , **el experimento del cerebro en una cubeta** o el **experimento de la prótesis cerebra** l.

**La ética y los riesgos de desarrollar la inteligencia artificial.**

Que podamos hacerlo es una cosa, que debamos hacerlo es otra. Los efectos de las nuevas tecnologías deben ser estudiados para definir si vale la pena o no invertir en ellos, ¿Hará más bien que mal la IA? Esta nueva tecnología viene de la mano de distintas nuevas problemáticas a las que hay que prestar atención:

• Las personas podrían perder sus trabajos por la automatización.

• Las personas podrían tener demasiado (o muy poco) tiempo de ocio.

• Las personas podrían perder el sentido de ser únicos.

• Las personas podrían perder algunos de sus derechos privados.

• La utilización de los sistemas de IA podría llevar a la pérdida de responsabilidad.

• El éxito de la IA podría significar el fin de la raza humana.

Algunas de estas problemáticas son bastante improbables, otras son problemáticas conjuntas de otras tecnologías y otras como por ejemplo la primera, ya lleva años pasando y no solo con la inteligencia artificial si no con cada nueva tecnología que ocurre, pero los empleos no se pierden, si no que se redireccionan a las nuevas áreas de trabajo creadas por la humanidad.

**Opiniones personales y pensamientos.**

¿Puede una máquina pensar inteligentemente? ¿Puede un programa sentir emociones? ¿Tener sentido del humor? Son preguntas injustas para juzgar a la IA, comparar cualidades que los seres humanos tardaron miles de millones de años en adquirir y compararla a las nuevas tecnologías para desacreditarlas viene de una falta de perspectiva.

Cuando pensamos en estas preguntas, debemos hacerlo pensando en las capacidades futuras de la tecnología, y en los conceptos que tenemos actualmente atada a ella. La inteligencia artificial es una herramienta, y su desarrollo irá marcando sus límites por lo que ponerle limitaciones a una tecnología tan joven como la IA sería hacer 200 años desestimar el primer vehículo a motor por no ir más rápido que un caballo. Imitar el comportamiento humano, aprobar el test de Turing, tener conciencia parecen tareas muy lejanas para la IA actualmente, de la misma manera que lo era poder volar hace 200 años para los motores.

La IA es una herramienta, y como todas las herramientas puede ser usada para acciones que beneficien al ser humano o que la perjudiquen, de la misma manera que el descubrimiento de la energía atómica nos trajo la capacidad de generar electricidad a grandes cantidades, también nos introdujo a las armas nucleares y el acercamiento a la idea de que el ser humano como raza conjunta puede ser vulnerable a sus invenciones.
