

Nombre: Carlos Perez

Legajo: 13245

**Inteligencia Artificial Débil:**

¿Puede una máquina actuar con inteligencia? Esta pregunta ha sido durante años la

razón de debate entre filósofos de la computación, en los cuales tenemos argumentos tan

fuertes y negativos como el de Kenneth M. Sayre:

*“La Inteligencia Artificial abordada desde dentro del culto al computacionalismo no*

*tendrá ni siquiera un atisbo de fantasma de posibilidad de producir resultados duraderos...*

*Es hora de desviar los esfuerzos de los investigadores en IA, y la gran cantidad de dinero*

*disponible para su soporte, y dirigirse a caminos distintos del enfoque computacional.”*

La IA es un concepto muy amplio que engloba extensas variables, por lo cual si esta

es posible o no está atada a la definición que le demos a tanto la inteligencia artificial como

al de inteligencia misma. Si tomamos la definición esencial de la IA, esta consiste en la

búsqueda del mejor programa agente en una arquitectura específica, entonces podemos

llegar al postulado que se define como:

*“La IA es posible por definición: para cualquier arquitectura digital de k bits de*

*almacenamiento existirán exactamente 2k programas agente y todo lo que habrá que hacer*

*para encontrar el mejor es enumerarlos y probar todos ellos”*

Si bien esta es una solución teórica, debido que para una k grande puede que no

logremos encontrar una solución práctica, cumple el objetivo de encontrar una definición

específica de lo que es la IA. Sin embargo la filosofía de la inteligencia artificial está

centrada en no solo definir la inteligencia artificial, si no definirla mediante la comparación

con la inteligencia humana, por lo que surge la pregunta: **¿Pueden pensar las máquinas?**

De nuevo estamos ante una pregunta en la cual la respuesta depende de las definiciones

que demos a un concepto, en este caso *pensar*, y debido a que el concepto de máquina

pensante lleva algo más de 50 años con nosotros, esto ha sido tiempo suficiente para

encontrar una definición específica del significado de *pensar.*

En 1950, Alan Turing sugirió que en vez de preguntar si las máquinas pueden

pensar, deberíamos preguntar si las máquinas pueden aprobar un test de inteligencia

inductiva, es decir un test de comportamiento, conocido como el Test de Turing. La prueba

se realiza para que el programa mantenga una conversación durante cinco minutos con un

interrogador. Este tiene que averiguar si la conversación se está llevando a cabo con un

programa o con una persona, si el programa engaña al interlocutor un 30 por ciento del

tiempo, este programa pasará la prueba. Si nos guiamos por esta definición, hoy en 2021 no

hay ningún programa en ninguna arquitectura que haya completado este test frente a jueces

con conocimiento sobre el área.





Turing examinó además una amplia gama de objeciones ante la posibilidad de las

máquinas inteligentes, algunas de ellas son:

\1. El argumento de la incapacidad:

Este argumento afirma que una máquina nunca puede hacer cosas como ser

amable, ser guapo, simpático, tener iniciativas, sentido del humor, cometer errores,

aprender de la experiencia, tener tanta diversidad de comportamientos como el hombre.

Turing se vio obligado a utilizar su intuición para listar este tipo de actividades. Hoy

en día muchas de estas actividades son de hecho, posibles para un computador, los

programas juegan ajedrez, damas, y a otros muchos juegos, comprueban errores

ortográficos, conducen coches y un largo etcétera de cosas que hacen tan bien como un ser

humano (Y en muchos casos, mejor). Pero esto no significa que los computadores utilizan la

intuición y el entendimiento para realizar estas tareas, y también es cierto que existen

muchas tareas en la actualidad en las que las computadoras no sobresalen.

\2. La objeción matemática:

Ciertas cuestiones matemáticas en principio no pueden ser respondidas por

sistemas formales completos, el teorema de la incompletitud de Gödel es el ejemplo más

conocido al respecto. Este dice que para cualquier sistema axiomático formal F lo

suficientemente potente como para hacer aritmética, es posible construir una *Sentencia de*

*Gödel* con las siguientes propiedades:

●

●

G(F) es una sentencia de F, pero no se puede probar dentro de F.

Si F es consistente, entonces G(F) es verdadero.

Filósofos han afirmado que este teorema demuestra que las máquinas son

mentalmente inferiores a los hombres, porque las máquinas son sistemas formales limitados

por el teorema de la incompletitud, es decir no pueden establecer la verdad de su propia

sentencia de Gödel. Existen algunos problemas con esta afirmación, aquí examinaremos 3.

En primer lugar el teorema de la incompletitud de Gödel se aplica sólo a sistemas

formales que son lo suficientemente potentes como para realizar aritmética. Aquí se

incluyen las máquinas Turing, y la afirmación se basa en que los computadores son

máquinas de Turing.

En segundo lugar, un agente no debería avergonzarse de no poder establecer

verdades de una sentencia aunque otros agentes si pueden, por ejemplo un ser humano no

puede calcular la suma de 10 billones de números de 10 digitos, pero una computadora si,

eso no quiere decir que el ser humano no tenga la habilidad de pensar. Diferentes

arquitecturas para diferentes problemas.





Y finalmente, aunque reconozcamos que los computadores tienen limitaciones sobre

lo que pueden demostrar, no existen evidencias de que los hombres sean inmunes a estas

limitaciones.

\3. El argumento de la informalidad:

“El comportamiento humano es demasiado complejo para poder captarse mediante

un simple juego de reglas” Esta es una de las principales críticas hacia la IA, esta idea

postula que como los computadores no pueden nada más que seguir un conjunto de reglas,

no pueden generar un comportamiento tan inteligente como el de los hombres.

Esta postura se llama “Good Old.Fashioned AI”, la cual afirma que todo

comportamiento inteligente puede ser capturado por un sistema que razona lógicamente,

esta afirmación fue dada por Hubert Dreyfus en 1972, bajo su punto de vista, la pericia del

hombre incluye el conocimiento de algunas reglas, pero solamente como un conocimiento

base dentro del que operan los hombres. Proporciona como ejemplo el comportamiento

social adecuado en ciertas situaciones entre humanos, como el elegir un regalo o en un

contexto diferente, elegir un movimiento en una partida de ajedrez, él afirma que un maestro

de ajedrez simplemente observa el tablero y analiza qué movimiento le exige este, es decir

cosas que no están abiertas a la introspección de la mente consciente. Sin embargo esto no

significa que no existan procesos de pensamientos inconscientes.

Dreyfus y Dreyfus (1986) proponen un proceso de adquisición de pericia en cinco

etapas, comenzando con un procesamiento basado en reglas y terminando con la habilidad

de seleccionar las respuestas correctas instantáneamente, este modelo se ha encontrado

con algunos problemas, afortunadamente se han abordados cada uno de estos, algunos

con éxito parcial y otro total.

●

No se puede lograr una buena generalización de ejemplos sin un

conocimiento básico. Se afirma que no se sabe cómo incorporar el

conocimiento básico en el proceso de aprendizaje, sin embargo actualmente

existen distintas técnicas de aprendizaje para programas de IA.

●

●

●

El aprendizaje de redes neuronales es una forma de aprendizaje supervisado

que requiere la identificación anterior de las entradas relevantes y las salidas

correctas, eso quiere decir que no puede funcionar autónomamente.

Los algoritmos de aprendizaje no funcionan bien con muchas funciones, si

seleccionamos un subgrupo de éstas no existe una forma de añadir

funciones nuevas.

El cerebro es capaz de dirigir sus sensores para buscar la información

relevante y procesarla para extraer aspectos relevantes para la situación

actual





**Inteligencia artificial fuerte:**

“ Hasta que una máquina pueda escribir un soneto o componer un concierto porque

sienta los pensamientos y las emociones, y no porque haya una lluvia de símbolos, podría

reconocer que la máquina iguala al cerebro, es decir, no sólo escribirlo sino que sepa que lo

ha hecho.”

Palabras dadas por el profesor Geoffrey Jefferson en 1949. Esto es a lo que Turing

llama el argumento de la consciencia, la máquina tiene que ser consciente de sus propias

acciones y estados mentales. La respuesta de Turing a esta objeción se basa en que la

cuestión no está bien definida al decir “¿Pueden pensar las máquinas?” y además Turing

preguntó que porqué deberíamos insistir en un estándar más alto para las máquinas que el

usado para los humanos, después de todo un ser humano no puede tener conciencia

directa sobre los estados mentales de otras personas.

Turing afirma que si bien la cuestión de la consciencia es difícil, niega que esta sea

relevante para la práctica de la IA, que se busca crear programas que se comporten de

forma inteligente y no en si alguien que los declara reales o simulados. El ser humano ha

tenido la capacidad ya desde hace décadas de crear componentes orgánicos de manera

artificial, desde la sintetización de la urea, edulcorantes artificiales, pasando por áreas como

la inseminación artificial y hasta la recreación artificial de obras de arte. Podemos

asegurarnos de que esos componentes artificiales son iguales química o físicamente a sus

contrapartes orgánicas, pero aún así existirá gente que asegure que una réplica no es igual

al original.

Existen 2 teorías de los estados y los procesos mentales que influyen en la

definición que estamos buscando:

\1. La teoría del funcionalismo dice que un estado mental es cualquier condición

causal inmediata entre la entrada y la salida, bajo esta teoría dos sistemas de

procesos causales isomórficos tendrán los mismos estados mentales.

\2. La teoría del naturalismo biológico dice que los estados mentales son

características emergentes de alto nivel originadas por procesos

neurológicos de bajo nivel en las neuronas, y lo que importan son sus

propiedades, así pues los estados mentales no se pueden duplicar justo en la

base de algún programa que tiene la misma estructura funcional

Estas dos teorías pueden ser aplicadas a distintos problemas filosóficos existentes

tales como el **problema de la mente-cuerpo**, **el experimento del cerebro en una cubeta**

o el **experimento de la prótesis cerebra**l.

**La ética y los riesgos de desarrollar la inteligencia artificial.**





Que podamos hacerlo es una cosa, que debamos hacerlo es otra. Los efectos de las

nuevas tecnologías deben ser estudiados para definir si vale la pena o no invertir en ellos,

¿Hará más bien que mal la IA? Esta nueva tecnología viene de la mano de distintas nuevas

problemáticas a las que hay que prestar atención:

• Las personas podrían perder sus trabajos por la automatización.

• Las personas podrían tener demasiado (o muy poco) tiempo de ocio.

• Las personas podrían perder el sentido de ser únicos.

• Las personas podrían perder algunos de sus derechos privados.

• La utilización de los sistemas de IA podría llevar a la pérdida de responsabilidad.

• El éxito de la IA podría significar el fin de la raza humana.

Algunas de estas problemáticas son bastante improbables, otras son problemáticas

conjuntas de otras tecnologías y otras como por ejemplo la primera, ya lleva años pasando

y no solo con la inteligencia artificial si no con cada nueva tecnología que ocurre, pero los

empleos no se pierden, si no que se redireccionan a las nuevas áreas de trabajo creadas

por la humanidad.

**Opiniones personales y pensamientos.**

¿Puede una máquina pensar inteligentemente? ¿Puede un programa sentir

emociones? ¿Tener sentido del humor? Son preguntas injustas para juzgar a la IA,

comparar cualidades que los seres humanos tardaron miles de millones de años en adquirir

y compararla a las nuevas tecnologías para desacreditarlas viene de una falta de

perspectiva.

Cuando pensamos en estas preguntas, debemos hacerlo pensando en las

capacidades futuras de la tecnología, y en los conceptos que tenemos actualmente atada a

ella. La inteligencia artificial es una herramienta, y su desarrollo irá marcando sus límites por

lo que ponerle limitaciones a una tecnología tan joven como la IA sería hacer 200 años

desestimar el primer vehículo a motor por no ir más rápido que un caballo. Imitar el

comportamiento humano, aprobar el test de Turing, tener conciencia parecen tareas muy

lejanas para la IA actualmente, de la misma manera que lo era poder volar hace 200 años

para los motores.

La IA es una herramienta, y como todas las herramientas puede ser usada para

acciones que beneficien al ser humano o que la perjudiquen, de la misma manera que el

descubrimiento de la energía atómica nos trajo la capacidad de generar electricidad a

grandes cantidades, también nos introdujo a las armas nucleares y el acercamiento a la

idea de que el ser humano como raza conjunta puede ser vulnerable a sus invenciones.

